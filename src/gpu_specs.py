"""
**This file is borrowed from KernelBench**
A List of GPU Specs to include in the prompt
"""


GPU_SPEC_INFO = {
    "RTX_4070_Laptop": {
        "GPU Architecture": "Ada",
        "GPU Memory": "8GB GDDR6",
        "Memory Bandwidth": "256 GB/s",
        "CUDA Cores": "4,608",
        "RT Cores": "36 (3rd generation)",
        "Tensor Cores": "144 (4th generation)",
        "FP32 TFLOPS": "15.6",
        "TGP (Total Graphics Power)": "35-140W (configurable)",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "24",
        "Shared memory capacity per SM": "100 KB",
        "Maximum shared memory per thread block": "99 KB",
    },
    "L40S": {
        "GPU Architecture": "Ada",
        "GPU Memory": "48GB GDDR6 with ECC",
        "Memory Bandwidth": "864 GB/s",
        "RT Core Performance TFLOPS": "212",
        "FP32 TFLOPS": "91.6",
        "TF32 Tensor Core TFLOPS": "183.2 (366 with sparsity)",
        "FP16 Tensor Core TFLOPS": "362.05 (733 with sparsity)",
        "FP8 Tensor Core TFLOPS": "733 (1466 with sparsity)",
        "Peak INT8 Tensor TOPS": "733 (1466 with sparsity)",
        "Peak INT4 Tensor TOPS": "733 (1466 with sparsity)",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "24",
        "Shared memory capacity per SM": "100 KB",
        "Maximum shared memory per thread block": "99 KB",
    },
    "H100": {
        "GPU Architecture": "Hopper",
        "GPU Memory": "80GB",
        "Memory Bandwidth": "3.35 TB/s",
        "FP64 TFLOPS": "34",
        "FP64 Tensor Core TFLOPS": "67",
        "FP32 TFLOPS": "67",
        "TF32 Tensor Core TFLOPS": "989 with sparsity",
        "BFLOAT16 Tensore Core TFLOPS": "1979 with sparsity",
        "FP16 Tensor Core TFLOPS": "1979 with sparsity",
        "FP8 Tensor Core TFLOPS": "3958 with sparsity",
        "INT8 Tensor Core TOPS": "3958 with sparsity",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "32",
        "Shared memory capacity per SM": "228 KB",
        "Maximum shared memory per thread block": "227 KB",
    },
    # this is 40GB (Standard)
    "A100": {
        "GPU Architecture": "Ampere",
        "GPU Memory": "40GB",
        "Memory Bandwidth": "1935 GB/s",
        "FP64 TFLOPS": "9.7",
        "FP64 Tensor Core TFLOPS": "19.5",
        "FP32 TFLOPS": "19.5",
        "TF32 Tensor Core TFLOPS": "156 (312 with sparsity)",
        "BFLOAT16 Tensore Core TFLOPS": "312 (624 with sparsity)",
        "FP16 Tensor Core TFLOPS": "312 (624 with sparsity)",
        "INT8 Tensor Core TOPS": "624 (1248 with sparsity)",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "32",
        "Shared memory capacity per SM": "164 KB",
        "Maximum shared memory per thread block": "163 KB",
    },
    "A100-80GB": {
        "GPU Architecture": "Ampere",
        "GPU Memory": "80GB",
        "Memory Bandwidth": "1935 GB/s",
        "FP64 TFLOPS": "9.7",
        "FP64 Tensor Core TFLOPS": "19.5",
        "FP32 TFLOPS": "19.5",
        "TF32 Tensor Core TFLOPS": "156 (312 with sparsity)",
        "BFLOAT16 Tensore Core TFLOPS": "312 (624 with sparsity)",
        "FP16 Tensor Core TFLOPS": "312 (624 with sparsity)",
        "INT8 Tensor Core TOPS": "624 (1248 with sparsity)",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "32",
        "Shared memory capacity per SM": "164 KB",
        "Maximum shared memory per thread block": "163 KB",
    },
    "L4": {
        "GPU Architecture": "Ada",
        "GPU Memory": "24GB",
        "Memory Bandwidth": "300 GB/s",
        "FP32 TFLOPS": "30.3",
        "TF32 Tensor Core TFLOPS": "120 with sparsity",
        "BFLOAT16 Tensore Core TFLOPS": "242 with sparsity",
        "FP8 Tensor Core TFLOPS": "485 with sparsity",
        "INT8 Tensor Core TOPS": "485 with sparsity",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "24",
        "Shared memory capacity per SM": "100 KB",
        "Maximum shared memory per thread block": "99 KB",
    }, 
    "T4": {
        "GPU Architecture": "Turing",
        "GPU Memory": "16 GB GDDR6",
        "Memory Bandwidth": "300 GB/s",
        "Single-Precision TFLOPS": "8.1",
        "Mixed-Precision (FP16/FP32) TFLOPS": "65",
        "INT8 TOPS": "130",
        "INT4 TOPS": "260",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "16",
        "Shared memory capacity per SM": "64 KB",
    },
    "A10G": {
        "GPU Architecture": "Ampere",
        "GPU Memory": "24GB GDDR6",
        "Memory Bandwidth": "600 GB/s",
        "FP32 TFLOPS": "31.2",
        "TF32 Tensor Core TFLOPS": "62.5 (125 with sparsity)",
        "BFLOAT16 Tensore Core TFLOPS": "125 (250 with sparsity)",
        "FP16 Tensor Core TFLOPS": "125 (250 with sparsity)",
        "INT8 Tensor Core TOPS": "250 (500 with sparsity)",
        "INT4 Tensor Core TOPS": "500 (1000 with sparsity)",
        "Register File Size": "64K 32-bit registers per SM",
        "Maximum number of registers per thread": "255",
        "Maximum number of thread blocks per SM": "32",
        "Shared memory capacity per SM": "164 KB",
        "Maximum shared memory per thread block": "163 KB",
    }
}

# Basic GPU concept definitions (Triton-focused)
GPU_DEFINITIONS = {
    "Program/Thread Block": "In Triton, a program instance processes a block of data. Each program maps to a CUDA thread block and operates on BLOCK_SIZE elements.",
    "program_id": "tl.program_id(axis) returns the index of the current program instance along a given axis, used to determine which block of data to process.",
    "BLOCK_SIZE": "A compile-time constant (tl.constexpr) that defines how many elements each program processes. Must be a power of 2 for optimal performance.",
    "Warp": "A group of 32 threads that execute in lockstep. Triton automatically manages warp-level operations for vectorized loads/stores.",
    "Shared Memory": "Fast on-chip memory shared by threads in a block. Triton implicitly uses it for block-level operations without explicit management.",
    "Register": "The fastest memory, private to each thread. Triton automatically allocates registers for intermediate computations.",
    "Memory Coalescing": "Accessing contiguous memory addresses across threads in a warp to maximize memory bandwidth. Triton encourages this through block operations.",
    "Memory Bandwidth": "The rate at which data can be transferred between GPU memory and compute units. Critical bottleneck for memory-bound operations.",
    "Tensor Cores": "Specialized hardware units for fast matrix operations. Use fp16/bf16/tf32 data types to leverage them in Triton kernels.",
    "Grid": "The arrangement of program instances launched. Defined as a lambda function in Triton: grid = lambda meta: (num_blocks,).",
    "Masking": "Using boolean masks in tl.load/tl.store to handle boundary conditions and prevent out-of-bounds memory accesses.",
    "Autotuning": "Triton's feature to automatically search for optimal BLOCK_SIZE and other parameters using the @triton.autotune decorator.",
}



GPU_BEST_PRACTICES = [
    # Triton-specific best practices
    # Adapted from Triton documentation and CUDA best practices
    "Choose optimal BLOCK_SIZE values - typically powers of 2 (128, 256, 512, 1024) for better hardware utilization.",
    "Minimize data transfers between CPU (host) and GPU (device) - keep data on GPU whenever possible.",
    "Use appropriate grid sizes to maximize SM (Streaming Multiprocessor) occupancy across the GPU.",
    "Ensure memory accesses are coalesced by using contiguous memory access patterns with tl.arange() and proper offsets.",
    "Leverage shared memory implicitly through Triton's block-level operations to reduce global memory accesses.",
    "Use masking (tl.load with mask parameter) to handle boundary conditions and avoid out-of-bounds accesses.",
    "Consider operator fusion - combine multiple operations (e.g., matmul + activation) into a single kernel to reduce memory traffic.",
    "Avoid branch divergence within a block - minimize conditional operations that vary across threads in the same warp.",
    "Use appropriate data types (fp16, bf16, fp32) based on the GPU architecture's tensor core capabilities for better performance.",
    "Leverage Triton's autotuning capabilities to find optimal kernel configurations for different input sizes.",
    "Consider algorithmic optimizations like online softmax, flash attention patterns, or tiling strategies for better cache utilization.",
]